{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139d4b2f",
   "metadata": {},
   "source": [
    "### Feature extractions\n",
    "\n",
    "This script responds to features extracted from two sentimental corpora, kt4.0 (ours) and wisesight. By combining train data from both corpora, we expect to see an improvement in the wisesight corpus' classification performance.\n",
    "\n",
    "For both datasets, random stratify hold-out was performed with 80:20 ratio for train and test set. Feature engineering was carried out including dictionary-based (i.e., using list of good and bad Thai words), word count approches. Next, several feature extraction methods were applied and output as a joblib objects as follows:  \n",
    "\n",
    "* BOW1, BOW2\n",
    "* TF-IDF1, TF-IDF2\n",
    "* Word2Vec pretrained from Thai wiki. (300 dimension)\n",
    "* POS_tagging with flatten dataframe\n",
    "\n",
    "Dependencies\n",
    "* pythainlp >= 3.06dev\n",
    "* python >= 3.8.8\n",
    "* gensim >= 4.1.2\n",
    "* scikit-learn >= 1.0.2\n",
    "* joblib = 1.1.0\n",
    "* dill = 0.31\n",
    "\n",
    "The output vectors will be carried out in the next experiment.  \n",
    "pree.t@cmu.ac.th  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a978d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pythainlp\n",
    "from pythainlp.ulmfit import process_thai\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'tahoma'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47e606a",
   "metadata": {},
   "source": [
    "## Load original datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe523d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60081, 14), (26737, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.dirname(os.getcwd())\n",
    "\n",
    "data_path_kt = os.path.dirname(os.getcwd()) + '\\\\data\\kt4.0\\\\'\n",
    "data_path_ws = os.path.dirname(os.getcwd()) + '\\\\data\\wisesight\\\\'\n",
    "df_kt = pd.read_csv(data_path_kt + 'pantip_cleaned_1.csv')\n",
    "\n",
    "# we use the original wisesight corpus and reconstruct a new dataframe\n",
    "texts = []\n",
    "targets = []\n",
    "\n",
    "with open(str(data_path_ws) + '/' + 'neg.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        texts.append(line.strip())\n",
    "        targets.append('neg')\n",
    "\n",
    "with open(str(data_path_ws) + '/' + 'neu.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        texts.append(line.strip())\n",
    "        targets.append('neu')\n",
    "\n",
    "with open(str(data_path_ws) + '/' + 'pos.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        texts.append(line.strip())\n",
    "        targets.append('pos')\n",
    "\n",
    "with open(str(data_path_ws) + '/' + 'q.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        texts.append(line.strip())\n",
    "        targets.append('q')\n",
    "        \n",
    "df_ws = pd.DataFrame({'texts': texts, 'targets': targets})\n",
    "df_ws.to_csv('wisesight.csv', index=False)\n",
    "df_kt.shape, df_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c128ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>emotion</th>\n",
       "      <th>length</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>label</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39839097</td>\n",
       "      <td>2020-04-25 13:24:00</td>\n",
       "      <td>https://pantip.com/profile/5798163</td>\n",
       "      <td>‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5798163</td>\n",
       "      <td>[CR] ‡πÅ‡∏õ‡∏±‡∏á‡∏û‡∏±‡∏ü‡∏Ñ‡∏∏‡∏°‡∏°‡∏±‡∏ô ‡∏à‡∏±‡∏î‡πÄ‡∏ï‡πá‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏ö‡∏≤‡∏á‡πÄ‡∏ö‡∏≤</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39839097</td>\n",
       "      <td>2020-04-25 13:24:00</td>\n",
       "      <td>https://pantip.com/profile/5798163</td>\n",
       "      <td>‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5798163</td>\n",
       "      <td>‡πÑ‡∏°‡πà‡∏≠‡∏∏‡∏î‡∏ï‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡∏õ‡∏Å‡∏õ‡∏¥‡∏î‡πÅ‡∏ô‡πà‡∏ô‡∏°‡∏≤‡∏Å</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39839097</td>\n",
       "      <td>2020-04-25 13:24:00</td>\n",
       "      <td>https://pantip.com/profile/5798163</td>\n",
       "      <td>‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5798163</td>\n",
       "      <td>‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÅ‡∏õ‡πâ‡∏á Lady Audrey Ready All Day ‡∏à‡πâ‡∏≤</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39838736</td>\n",
       "      <td>2020-04-25 10:52:00</td>\n",
       "      <td>https://pantip.com/profile/5730006</td>\n",
       "      <td>‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5730006</td>\n",
       "      <td>‡∏Ç‡∏≠‡∏ö‡∏ï‡∏≤‡∏î‡∏≥‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏Ñ‡∏≠‡∏£‡πå‡πÄ‡∏•‡πá‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡πá‡πÄ‡∏≠‡∏≤‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39837384</td>\n",
       "      <td>2020-04-24 20:39:00</td>\n",
       "      <td>https://pantip.com/profile/4975838</td>\n",
       "      <td>‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 4975838</td>\n",
       "      <td>‡πÄ‡∏≠‡∏≤aloe Vera ‡πÅ‡∏ä‡πà‡∏ï‡∏π‡πâ‡πÄ‡∏¢‡πá‡∏ô ‡∏à‡∏ô‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡πâ‡∏≥‡πÅ‡∏Ç‡πá‡∏á</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39838990</td>\n",
       "      <td>2020-04-25 12:36:00</td>\n",
       "      <td>https://pantip.com/profile/5655853</td>\n",
       "      <td>chdewxx</td>\n",
       "      <td>[SR] ‡πÑ‡∏≠‡πÄ‡∏ó‡∏° #‡πÄ‡∏ã‡∏£‡∏±‡πà‡∏°‡∏™‡∏¥‡∏ß ‡∏•‡∏î‡∏™‡∏¥‡∏ß ‡∏™‡∏¥‡∏ß‡∏≠‡∏∏‡∏î‡∏ï‡∏±‡∏ô ‡∏™‡∏¥‡∏ß‡∏ú‡∏î ‡∏ö‡∏≥...</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>39838619</td>\n",
       "      <td>2020-04-25 10:01:00</td>\n",
       "      <td>https://pantip.com/profile/5656639</td>\n",
       "      <td>‡∏Ñ‡∏π‡∏à‡∏≠‡∏á‡∏¢‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏ß‡∏µ‡∏£‡∏¢‡∏≤</td>\n",
       "      <td>‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏™‡∏≤‡∏ß‡πÜ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏Å‡∏¥‡∏ô‡πÅ‡∏Ñ‡∏£‡πå ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ú‡∏¥‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏≤...</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>39837266</td>\n",
       "      <td>2020-04-24 19:58:00</td>\n",
       "      <td>https://pantip.com/profile/632132</td>\n",
       "      <td>‡∏´‡∏°‡∏π‡∏Å‡∏•‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏î‡∏µ</td>\n",
       "      <td>‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ ‡πÅ‡∏Ñ‡∏£‡∏≠‡∏ó‡∏ß‡∏¥‡∏ï‡∏ã‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏™</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39837266</td>\n",
       "      <td>2020-04-24 19:58:00</td>\n",
       "      <td>https://pantip.com/profile/632132</td>\n",
       "      <td>‡∏´‡∏°‡∏π‡∏Å‡∏•‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏î‡∏µ</td>\n",
       "      <td>‡πÉ‡∏ô 1 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39835926</td>\n",
       "      <td>2020-04-24 12:03:00</td>\n",
       "      <td>https://pantip.com/profile/3826851</td>\n",
       "      <td>‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 3826851</td>\n",
       "      <td>‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å \"‡∏£‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô\" ‡πÅ‡∏•‡∏∞ \"‡∏Ñ‡∏≠‡∏ô‡∏ã‡∏µ‡∏•‡πÄ‡∏•‡∏≠‡∏£‡πå\"</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    post_id            post_date                             user_id  \\\n",
       "0  39839097  2020-04-25 13:24:00  https://pantip.com/profile/5798163   \n",
       "1  39839097  2020-04-25 13:24:00  https://pantip.com/profile/5798163   \n",
       "2  39839097  2020-04-25 13:24:00  https://pantip.com/profile/5798163   \n",
       "3  39838736  2020-04-25 10:52:00  https://pantip.com/profile/5730006   \n",
       "4  39837384  2020-04-24 20:39:00  https://pantip.com/profile/4975838   \n",
       "5  39838990  2020-04-25 12:36:00  https://pantip.com/profile/5655853   \n",
       "6  39838619  2020-04-25 10:01:00  https://pantip.com/profile/5656639   \n",
       "7  39837266  2020-04-24 19:58:00   https://pantip.com/profile/632132   \n",
       "8  39837266  2020-04-24 19:58:00   https://pantip.com/profile/632132   \n",
       "9  39835926  2020-04-24 12:03:00  https://pantip.com/profile/3826851   \n",
       "\n",
       "               user_name                                               text  \\\n",
       "0  ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5798163              [CR] ‡πÅ‡∏õ‡∏±‡∏á‡∏û‡∏±‡∏ü‡∏Ñ‡∏∏‡∏°‡∏°‡∏±‡∏ô ‡∏à‡∏±‡∏î‡πÄ‡∏ï‡πá‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏ö‡∏≤‡∏á‡πÄ‡∏ö‡∏≤   \n",
       "1  ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5798163                          ‡πÑ‡∏°‡πà‡∏≠‡∏∏‡∏î‡∏ï‡∏±‡∏ô ‡πÅ‡∏ï‡πà‡∏õ‡∏Å‡∏õ‡∏¥‡∏î‡πÅ‡∏ô‡πà‡∏ô‡∏°‡∏≤‡∏Å   \n",
       "2  ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5798163            ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß‡πÅ‡∏õ‡πâ‡∏á Lady Audrey Ready All Day ‡∏à‡πâ‡∏≤   \n",
       "3  ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5730006            ‡∏Ç‡∏≠‡∏ö‡∏ï‡∏≤‡∏î‡∏≥‡∏°‡∏≤‡∏Å‡∏Ñ‡πà‡∏∞ ‡∏Ñ‡∏≠‡∏£‡πå‡πÄ‡∏•‡πá‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡πá‡πÄ‡∏≠‡∏≤‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà   \n",
       "4  ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 4975838          ‡πÄ‡∏≠‡∏≤aloe Vera ‡πÅ‡∏ä‡πà‡∏ï‡∏π‡πâ‡πÄ‡∏¢‡πá‡∏ô ‡∏à‡∏ô‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡πâ‡∏≥‡πÅ‡∏Ç‡πá‡∏á   \n",
       "5                chdewxx  [SR] ‡πÑ‡∏≠‡πÄ‡∏ó‡∏° #‡πÄ‡∏ã‡∏£‡∏±‡πà‡∏°‡∏™‡∏¥‡∏ß ‡∏•‡∏î‡∏™‡∏¥‡∏ß ‡∏™‡∏¥‡∏ß‡∏≠‡∏∏‡∏î‡∏ï‡∏±‡∏ô ‡∏™‡∏¥‡∏ß‡∏ú‡∏î ‡∏ö‡∏≥...   \n",
       "6       ‡∏Ñ‡∏π‡∏à‡∏≠‡∏á‡∏¢‡∏≠‡∏ô‡πÅ‡∏•‡∏∞‡∏ß‡∏µ‡∏£‡∏¢‡∏≤  ‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏™‡∏≤‡∏ß‡πÜ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏Å‡∏¥‡∏ô‡πÅ‡∏Ñ‡∏£‡πå ‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ‡∏ú‡∏¥‡∏ß‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏≤...   \n",
       "7         ‡∏´‡∏°‡∏π‡∏Å‡∏•‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏î‡∏µ                          ‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ ‡πÅ‡∏Ñ‡∏£‡∏≠‡∏ó‡∏ß‡∏¥‡∏ï‡∏ã‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏™   \n",
       "8         ‡∏´‡∏°‡∏π‡∏Å‡∏•‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏î‡∏µ                                       ‡πÉ‡∏ô 1 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå   \n",
       "9  ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 3826851              ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å \"‡∏£‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô\" ‡πÅ‡∏•‡∏∞ \"‡∏Ñ‡∏≠‡∏ô‡∏ã‡∏µ‡∏•‡πÄ‡∏•‡∏≠‡∏£‡πå\"   \n",
       "\n",
       "            tag                                          emotion  length  \\\n",
       "0  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      36   \n",
       "1  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      36   \n",
       "2  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      36   \n",
       "3  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      15   \n",
       "4  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      11   \n",
       "5  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      29   \n",
       "6  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      23   \n",
       "7  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      14   \n",
       "8  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      14   \n",
       "9  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      14   \n",
       "\n",
       "   num_sent  sent_length  label  label_1  label_2 vote  \n",
       "0         3           14      2        2        2  pos  \n",
       "1         3            8      2        2        2  pos  \n",
       "2         3           14      2        2        1  pos  \n",
       "3         2           13      1        3        3  neg  \n",
       "4         1           11      1        1        3  neu  \n",
       "5         1           29      2        2        2  pos  \n",
       "6         1           23      2        2        1  pos  \n",
       "7         2            9      1        2        2  pos  \n",
       "8         2            5      1        1        1  neu  \n",
       "9         1           14      2        2        2  pos  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84766f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>length</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>label</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.008100e+04</td>\n",
       "      <td>60081.000000</td>\n",
       "      <td>60081.000000</td>\n",
       "      <td>60081.000000</td>\n",
       "      <td>60081.000000</td>\n",
       "      <td>60081.000000</td>\n",
       "      <td>60081.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.964936e+07</td>\n",
       "      <td>116.994574</td>\n",
       "      <td>8.502172</td>\n",
       "      <td>13.978329</td>\n",
       "      <td>1.577304</td>\n",
       "      <td>1.362644</td>\n",
       "      <td>1.662156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.559919e+05</td>\n",
       "      <td>118.647716</td>\n",
       "      <td>7.575442</td>\n",
       "      <td>12.083572</td>\n",
       "      <td>0.777527</td>\n",
       "      <td>0.639271</td>\n",
       "      <td>0.800034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.917283e+07</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.958755e+07</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.968929e+07</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.976947e+07</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.983970e+07</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            post_id        length      num_sent   sent_length         label  \\\n",
       "count  6.008100e+04  60081.000000  60081.000000  60081.000000  60081.000000   \n",
       "mean   3.964936e+07    116.994574      8.502172     13.978329      1.577304   \n",
       "std    1.559919e+05    118.647716      7.575442     12.083572      0.777527   \n",
       "min    3.917283e+07      3.000000      1.000000      3.000000      1.000000   \n",
       "25%    3.958755e+07     31.000000      3.000000      6.000000      1.000000   \n",
       "50%    3.968929e+07     72.000000      6.000000     10.000000      1.000000   \n",
       "75%    3.976947e+07    159.000000     11.000000     17.000000      2.000000   \n",
       "max    3.983970e+07    499.000000     44.000000    301.000000      3.000000   \n",
       "\n",
       "            label_1       label_2  \n",
       "count  60081.000000  60081.000000  \n",
       "mean       1.362644      1.662156  \n",
       "std        0.639271      0.800034  \n",
       "min        1.000000      1.000000  \n",
       "25%        1.000000      1.000000  \n",
       "50%        1.000000      1.000000  \n",
       "75%        2.000000      2.000000  \n",
       "max        3.000000      3.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ec5386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚òπÔ∏è</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üòî</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üòû</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üò•</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡∏£‡∏≥</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No‡πÜ</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rip</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T_T</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>‡∏Å‡∏≤‡∏Å</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>‡πÇ‡∏Å‡∏á</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  texts targets\n",
       "0    ‚òπÔ∏è     neg\n",
       "1     üòî     neg\n",
       "2     üòû     neg\n",
       "3     üò•     neg\n",
       "4    ‡∏£‡∏≥     neg\n",
       "5   No‡πÜ     neg\n",
       "6   Rip     neg\n",
       "7   T_T     neg\n",
       "8   ‡∏Å‡∏≤‡∏Å     neg\n",
       "9   ‡πÇ‡∏Å‡∏á     neg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ws.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7077f068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26737</td>\n",
       "      <td>26737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>26713</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>‡∏≠‡∏∏‡∏î‡∏£‡∏°‡∏µ‡πÑ‡∏´‡∏°‡∏Ñ‡πà‡∏∞</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>14561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               texts targets\n",
       "count          26737   26737\n",
       "unique         26713       4\n",
       "top     ‡∏≠‡∏∏‡∏î‡∏£‡∏°‡∏µ‡πÑ‡∏´‡∏°‡∏Ñ‡πà‡∏∞     neu\n",
       "freq               2   14561"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ws.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75693314",
   "metadata": {},
   "source": [
    "# Train-test split 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c67990d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48064, 14), (12017, 14))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random stratified split train and test set 80/20\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "all_df_kt, test_df_kt = train_test_split(df_kt, test_size=0.2, random_state=42, shuffle = True)\n",
    "all_df_kt.shape, test_df_kt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c7d3bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    0.632136\n",
       "pos    0.206620\n",
       "neg    0.161243\n",
       "Name: vote, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "all_df_kt.vote.value_counts() / all_df_kt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b63ee3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21389, 2), (5348, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_ws, test_df_ws = train_test_split(df_ws, test_size=0.2, random_state=42)\n",
    "all_df_ws.shape, test_df_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae548ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    0.544860\n",
       "neg    0.253588\n",
       "pos    0.179345\n",
       "q      0.022208\n",
       "Name: targets, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "all_df_ws.targets.value_counts() / all_df_ws.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ef6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and word tokenize\n",
    "all_df_kt['processed'] = all_df_kt['text'].apply(str).apply(process_thai)\n",
    "test_df_kt['processed'] = test_df_kt['text'].apply(str).apply(process_thai)\n",
    "\n",
    "all_df_ws['processed'] = all_df_ws['texts'].apply(str).apply(process_thai)\n",
    "test_df_ws['processed'] = test_df_ws['texts'].apply(str).apply(process_thai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6949e",
   "metadata": {},
   "source": [
    "## Feature engineering: dictionary-based, word count, and unique word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e922a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature with dict-based approach\n",
    "# load list of our custom positive and negative words\n",
    "with open(os.path.dirname(os.getcwd()) + '\\\\data\\\\' + 'pos_words.txt', encoding='UTF-8') as f:\n",
    "    pos_words = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "with open(os.path.dirname(os.getcwd()) + '\\\\data\\\\' + 'neg_words.txt', encoding='UTF-8') as f:\n",
    "    neg_words = [line.rstrip('\\n') for line in f]\n",
    "pos_words = list(set(pos_words))\n",
    "neg_words = list(set(neg_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ad848e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sentiment(sentence):\n",
    "    senti = 0\n",
    "    words = [word.lower() for word in sentence]\n",
    "    for word in words:\n",
    "        if word in pos_words:\n",
    "            senti += 1\n",
    "        elif word in neg_words:\n",
    "            senti -= 1\n",
    "    return senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fa19d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>emotion</th>\n",
       "      <th>length</th>\n",
       "      <th>num_sent</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>label</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>vote</th>\n",
       "      <th>processed</th>\n",
       "      <th>cal_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43487</th>\n",
       "      <td>39420424</td>\n",
       "      <td>2019-11-19 12:36:00</td>\n",
       "      <td>https://pantip.com/profile/3561069</td>\n",
       "      <td>‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 3561069</td>\n",
       "      <td>‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÅ‡∏•‡∏∞‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö Zinc Vistra 2...</td>\n",
       "      <td>‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏™‡∏£‡∏¥‡∏°</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>197</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neu</td>\n",
       "      <td>[‡∏ï‡∏≤‡∏°, ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠, ‡πÅ‡∏•‡∏∞, ‡∏ï‡∏≤‡∏°, ‡∏£‡∏π‡∏õ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö, ‡πÄ‡∏•‡∏¢, ‡∏Ñ‡∏£‡∏±‡∏ö, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31804</th>\n",
       "      <td>39711716</td>\n",
       "      <td>2020-03-13 15:14:00</td>\n",
       "      <td>https://pantip.com/profile/162639</td>\n",
       "      <td>PANTIP CREW</td>\n",
       "      <td>‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô Expert Account ‡πÉ‡∏ô‡∏ô‡∏≤‡∏°‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏¥‡∏ô pholfoo...</td>\n",
       "      <td>‡∏≠‡∏≤‡∏´‡∏≤‡∏£</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 5 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>154</td>\n",
       "      <td>8</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>[‡πÅ‡∏•‡∏∞, ‡∏¢‡∏±‡∏á, ‡πÄ‡∏õ‡πá‡∏ô, expert, account, ‡πÉ‡∏ô‡∏ô‡∏≤‡∏°, ‡∏•‡πá‡∏≠‡∏Å‡∏≠...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>39646166</td>\n",
       "      <td>2020-02-17 16:39:00</td>\n",
       "      <td>https://pantip.com/profile/5746727</td>\n",
       "      <td>‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5746727</td>\n",
       "      <td>‡∏≠‡∏¢‡∏≤‡∏Å‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≤‡∏ß‡πÉ‡∏™ ‡πÅ‡∏ï‡πà‡∏Ç‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡∏¢‡∏à‡∏ó‡∏≤‡∏Ñ‡∏£‡∏µ‡∏°</td>\n",
       "      <td>‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏™‡∏£‡∏¥‡∏°</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>neu</td>\n",
       "      <td>[‡∏≠‡∏¢‡∏≤‡∏Å, ‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≤‡∏ß, ‡πÉ‡∏™, ‡πÅ‡∏ï‡πà, ‡∏Ç‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡∏¢‡∏à, ‡∏ó‡∏≤, ‡∏Ñ‡∏£‡∏µ‡∏°]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>39763266</td>\n",
       "      <td>2020-03-31 19:43:00</td>\n",
       "      <td>https://pantip.com/profile/567821</td>\n",
       "      <td>sugarsand</td>\n",
       "      <td>‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠ 31 ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏° ‡πÄ‡∏ß‡∏•‡∏≤ 19:55 ‡∏ô.</td>\n",
       "      <td>‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>96</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neu</td>\n",
       "      <td>[‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç, ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡πÄ‡∏°‡∏∑‡πà‡∏≠, 31, ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°, ‡πÄ‡∏ß‡∏•‡∏≤, 19, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27651</th>\n",
       "      <td>39762185</td>\n",
       "      <td>2020-03-31 20:48:00</td>\n",
       "      <td>https://pantip.com/profile/674738</td>\n",
       "      <td>lantaolhin</td>\n",
       "      <td>‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏£‡∏π‡πâ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏Å‡πá‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏≠‡∏á</td>\n",
       "      <td>‡∏≠‡∏≤‡∏´‡∏≤‡∏£</td>\n",
       "      <td>‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neu</td>\n",
       "      <td>[‡πÄ‡∏û‡∏¥‡πà‡∏á, ‡∏£‡∏π‡πâ, ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•, ‡∏ó‡∏µ‡πà, ‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á, ‡∏Å‡πá, ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        post_id            post_date                             user_id  \\\n",
       "43487  39420424  2019-11-19 12:36:00  https://pantip.com/profile/3561069   \n",
       "31804  39711716  2020-03-13 15:14:00   https://pantip.com/profile/162639   \n",
       "3000   39646166  2020-02-17 16:39:00  https://pantip.com/profile/5746727   \n",
       "8760   39763266  2020-03-31 19:43:00   https://pantip.com/profile/567821   \n",
       "27651  39762185  2020-03-31 20:48:00   https://pantip.com/profile/674738   \n",
       "\n",
       "                   user_name  \\\n",
       "43487  ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 3561069   \n",
       "31804            PANTIP CREW   \n",
       "3000   ‡∏™‡∏°‡∏≤‡∏ä‡∏¥‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç 5746727   \n",
       "8760               sugarsand   \n",
       "27651             lantaolhin   \n",
       "\n",
       "                                                    text           tag  \\\n",
       "43487  ‡∏ï‡∏≤‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÅ‡∏•‡∏∞‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö Zinc Vistra 2...    ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏™‡∏£‡∏¥‡∏°   \n",
       "31804  ‡πÅ‡∏•‡∏∞‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô Expert Account ‡πÉ‡∏ô‡∏ô‡∏≤‡∏°‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏¥‡∏ô pholfoo...         ‡∏≠‡∏≤‡∏´‡∏≤‡∏£   \n",
       "3000                      ‡∏≠‡∏¢‡∏≤‡∏Å‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≤‡∏ß‡πÉ‡∏™ ‡πÅ‡∏ï‡πà‡∏Ç‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡∏¢‡∏à‡∏ó‡∏≤‡∏Ñ‡∏£‡∏µ‡∏°    ‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÄ‡∏™‡∏£‡∏¥‡∏°   \n",
       "8760           ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠ 31 ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏° ‡πÄ‡∏ß‡∏•‡∏≤ 19:55 ‡∏ô.  ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á   \n",
       "27651                ‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏£‡∏π‡πâ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏Å‡πá‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏≠‡∏á         ‡∏≠‡∏≤‡∏´‡∏≤‡∏£   \n",
       "\n",
       "                                               emotion  length  num_sent  \\\n",
       "43487  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0     197        11   \n",
       "31804  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 5 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0     154         8   \n",
       "3000   ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      16         2   \n",
       "8760   ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      96         3   \n",
       "27651  ‡∏ñ‡∏π‡∏Å‡πÉ‡∏à 0 ‡∏Ç‡∏≥‡∏Å‡∏•‡∏¥‡πâ‡∏á 0 ‡∏´‡∏•‡∏á‡∏£‡∏±‡∏Å 0 ‡∏ã‡∏∂‡πâ‡∏á 0 ‡∏™‡∏¢‡∏≠‡∏á 0 ‡∏ó‡∏∂‡πà‡∏á 0      21         3   \n",
       "\n",
       "       sent_length  label  label_1  label_2 vote  \\\n",
       "43487           18      1        1        1  neu   \n",
       "31804           43      1        2        2  pos   \n",
       "3000             9      1        1        3  neu   \n",
       "8760            16      1        1        1  neu   \n",
       "27651            9      1        1        1  neu   \n",
       "\n",
       "                                               processed  cal_sentiment  \n",
       "43487  [‡∏ï‡∏≤‡∏°, ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠, ‡πÅ‡∏•‡∏∞, ‡∏ï‡∏≤‡∏°, ‡∏£‡∏π‡∏õ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö, ‡πÄ‡∏•‡∏¢, ‡∏Ñ‡∏£‡∏±‡∏ö, ...              0  \n",
       "31804  [‡πÅ‡∏•‡∏∞, ‡∏¢‡∏±‡∏á, ‡πÄ‡∏õ‡πá‡∏ô, expert, account, ‡πÉ‡∏ô‡∏ô‡∏≤‡∏°, ‡∏•‡πá‡∏≠‡∏Å‡∏≠...              0  \n",
       "3000         [‡∏≠‡∏¢‡∏≤‡∏Å, ‡∏ú‡∏¥‡∏ß‡∏Ç‡∏≤‡∏ß, ‡πÉ‡∏™, ‡πÅ‡∏ï‡πà, ‡∏Ç‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡∏¢‡∏à, ‡∏ó‡∏≤, ‡∏Ñ‡∏£‡∏µ‡∏°]              0  \n",
       "8760   [‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç, ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°, ‡πÄ‡∏°‡∏∑‡πà‡∏≠, 31, ‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°, ‡πÄ‡∏ß‡∏•‡∏≤, 19, ...              0  \n",
       "27651  [‡πÄ‡∏û‡∏¥‡πà‡∏á, ‡∏£‡∏π‡πâ, ‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•, ‡∏ó‡∏µ‡πà, ‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á, ‡∏Å‡πá, ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ,...              0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_kt['cal_sentiment'] = all_df_kt['processed'].apply(cal_sentiment)\n",
    "all_df_ws['cal_sentiment'] = all_df_ws['processed'].apply(cal_sentiment)\n",
    "\n",
    "test_df_kt['cal_sentiment'] = test_df_kt['processed'].apply(cal_sentiment)\n",
    "test_df_ws['cal_sentiment'] = test_df_ws['processed'].apply(cal_sentiment)\n",
    "all_df_kt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3485a4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>targets</th>\n",
       "      <th>processed</th>\n",
       "      <th>cal_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25232</th>\n",
       "      <td>Nissan Silvia S14 ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏°‡∏π‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡πà‡∏´‡πå‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÉ‡∏Ñ‡∏£ ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>[nissan, silvia, s, 14, ‡∏´‡∏ô‡πâ‡∏≤, ‡∏´‡∏°‡∏π, ‡∏ó‡∏µ‡πà, ‡πÄ‡∏ó‡πà‡∏´‡πå,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11150</th>\n",
       "      <td>‡πÑ‡∏õ‡∏î‡∏π‡∏´‡∏ô‡∏±‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏±‡πâ‡∏¢‡∏à‡πâ‡∏∞‡∏ß‡∏¥</td>\n",
       "      <td>neu</td>\n",
       "      <td>[‡πÑ‡∏õ‡∏î‡∏π, ‡∏´‡∏ô‡∏±‡∏á, ‡∏Å‡∏±‡∏ô, ‡∏°‡∏±‡πâ‡∏¢, ‡∏à‡πâ‡∏∞, ‡∏ß‡∏¥]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23799</th>\n",
       "      <td>‡∏î‡∏±‡∏ô.....‡πÜ‡∏Ñ‡∏£‡∏±‡∏ö....‡πÄ‡∏≠‡∏≤‡∏î‡πâ‡∏ß‡∏¢</td>\n",
       "      <td>pos</td>\n",
       "      <td>[‡∏î‡∏±‡∏ô, ., xxrep, ‡πÜ, ‡∏Ñ‡∏£‡∏±‡∏ö, ., xxrep, ‡πÄ‡∏≠‡∏≤, ‡∏î‡πâ‡∏ß‡∏¢]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>‡∏Ñ‡∏∑‡∏ô‡∏ô‡∏µ‡πâ Chang Carnival World of Illusion ‡∏ó‡∏µ‡πà‡∏•‡∏≤‡∏ô...</td>\n",
       "      <td>neu</td>\n",
       "      <td>[‡∏Ñ‡∏∑‡∏ô‡∏ô‡∏µ‡πâ, chang, carnival, world, of, illusion,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12291</th>\n",
       "      <td>‡∏à‡∏±‡∏î‡πÑ‡∏´‡πâ‡∏ô‡πâ‡∏≤‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏î‡∏¥‡∏ï‡∏±‡∏á‡∏≠‡∏≠‡∏Å‡∏≠‡πà‡∏∞</td>\n",
       "      <td>neu</td>\n",
       "      <td>[‡∏à‡∏±‡∏î, ‡πÑ‡∏´‡πâ, ‡∏ô‡πâ‡∏≤, ‡∏´‡∏ô‡πà‡∏≠‡∏¢, ‡∏î‡∏¥, ‡∏ï‡∏±‡∏á, ‡∏≠‡∏≠‡∏Å, ‡∏≠‡πà‡∏∞]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texts targets  \\\n",
       "25232  Nissan Silvia S14 ‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏°‡∏π‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡πà‡∏´‡πå‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÉ‡∏Ñ‡∏£ ...     pos   \n",
       "11150                               ‡πÑ‡∏õ‡∏î‡∏π‡∏´‡∏ô‡∏±‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏±‡πâ‡∏¢‡∏à‡πâ‡∏∞‡∏ß‡∏¥     neu   \n",
       "23799                           ‡∏î‡∏±‡∏ô.....‡πÜ‡∏Ñ‡∏£‡∏±‡∏ö....‡πÄ‡∏≠‡∏≤‡∏î‡πâ‡∏ß‡∏¢     pos   \n",
       "19312  ‡∏Ñ‡∏∑‡∏ô‡∏ô‡∏µ‡πâ Chang Carnival World of Illusion ‡∏ó‡∏µ‡πà‡∏•‡∏≤‡∏ô...     neu   \n",
       "12291                          ‡∏à‡∏±‡∏î‡πÑ‡∏´‡πâ‡∏ô‡πâ‡∏≤‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏î‡∏¥‡∏ï‡∏±‡∏á‡∏≠‡∏≠‡∏Å‡∏≠‡πà‡∏∞     neu   \n",
       "\n",
       "                                               processed  cal_sentiment  \n",
       "25232  [nissan, silvia, s, 14, ‡∏´‡∏ô‡πâ‡∏≤, ‡∏´‡∏°‡∏π, ‡∏ó‡∏µ‡πà, ‡πÄ‡∏ó‡πà‡∏´‡πå,...              0  \n",
       "11150                   [‡πÑ‡∏õ‡∏î‡∏π, ‡∏´‡∏ô‡∏±‡∏á, ‡∏Å‡∏±‡∏ô, ‡∏°‡∏±‡πâ‡∏¢, ‡∏à‡πâ‡∏∞, ‡∏ß‡∏¥]              0  \n",
       "23799      [‡∏î‡∏±‡∏ô, ., xxrep, ‡πÜ, ‡∏Ñ‡∏£‡∏±‡∏ö, ., xxrep, ‡πÄ‡∏≠‡∏≤, ‡∏î‡πâ‡∏ß‡∏¢]              0  \n",
       "19312  [‡∏Ñ‡∏∑‡∏ô‡∏ô‡∏µ‡πâ, chang, carnival, world, of, illusion,...              0  \n",
       "12291          [‡∏à‡∏±‡∏î, ‡πÑ‡∏´‡πâ, ‡∏ô‡πâ‡∏≤, ‡∏´‡∏ô‡πà‡∏≠‡∏¢, ‡∏î‡∏¥, ‡∏ï‡∏±‡∏á, ‡∏≠‡∏≠‡∏Å, ‡∏≠‡πà‡∏∞]              0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_ws.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e0bb454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17576646507820368 0.11384882038831483\n"
     ]
    }
   ],
   "source": [
    "# see the correlation between the above computational sentiment and human ratings \n",
    "# for train set\n",
    "all_df_kt['targets_codes'] = all_df_kt['vote'].astype('category').cat.codes\n",
    "all_df_ws['targets_codes'] = all_df_ws['targets'].astype('category').cat.codes\n",
    "\n",
    "# for test set\n",
    "test_df_kt['targets_codes'] = test_df_kt['vote'].astype('category').cat.codes\n",
    "test_df_ws['targets_codes'] = test_df_ws['targets'].astype('category').cat.codes\n",
    "\n",
    "print(all_df_kt['targets_codes'].corr(all_df_kt['cal_sentiment']), \\\n",
    "      all_df_ws['targets_codes'].corr(all_df_ws['cal_sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9787b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word count feature\n",
    "all_df_kt = all_df_kt.rename(columns = {'sent_length':'wc'})\n",
    "all_df_ws['wc'] =  all_df_ws['processed'].map(len)\n",
    "\n",
    "test_df_kt = all_df_kt.rename(columns = {'sent_length':'wc'})\n",
    "test_df_ws['wc'] =  test_df_ws['processed'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77849de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01440540432656602 -0.0728353149652106\n"
     ]
    }
   ],
   "source": [
    "# see if the a correlation with word count\n",
    "print(all_df_kt['targets_codes'].corr(all_df_kt['wc']), \\\n",
    "      all_df_ws['targets_codes'].corr(all_df_ws['wc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "350cbcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_df_kt.to_csv('all_df_kt.csv',  index=False)\n",
    "#test_df_kt.to_csv('test_df_kt.csv',  index=False)\n",
    "\n",
    "all_df_ws.to_csv('all_df_ws.csv', index=False)\n",
    "test_df_ws.to_csv('test_df_ws.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6e20f",
   "metadata": {},
   "source": [
    "## Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2eb3e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bow2_fit_ws_kt.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import joblib\n",
    "\n",
    "# BOW with unigram and bigrams\n",
    "bow1 = CountVectorizer(ngram_range=(1, 1))\n",
    "bow2 = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "bow1_fit_ws = bow1.fit(all_df_ws['processed'].apply(str))\n",
    "bow1_fit_ws_kt = bow1_fit_ws.fit(all_df_kt['processed'].apply(str))\n",
    "\n",
    "bow2_fit_ws = bow2.fit(all_df_ws['processed'].apply(str))\n",
    "bow2_fit_ws_kt = bow2_fit_ws.fit(all_df_kt['processed'].apply(str))\n",
    "\n",
    "joblib.dump(bow1_fit_ws, 'bow1_fit_ws.pkl')\n",
    "joblib.dump(bow1_fit_ws_kt, 'bow1_fit_ws_kt.pkl')\n",
    "joblib.dump(bow2_fit_ws, 'bow2_fit_ws.pkl')\n",
    "joblib.dump(bow2_fit_ws_kt, 'bow2_fit_ws_kt.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d7b552",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3232d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf2_fit_ws_kt.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf1 = TfidfVectorizer(ngram_range=(1, 1), min_df=20, sublinear_tf=True)\n",
    "tfidf2 = TfidfVectorizer(ngram_range=(2, 2), min_df=20, sublinear_tf=True)\n",
    "\n",
    "tfidf1_fit_ws = tfidf1.fit(all_df_ws['processed'].apply(str))\n",
    "tfidf1_fit_ws_kt = tfidf1_fit_ws.fit(all_df_kt['processed'].apply(str))\n",
    "\n",
    "tfidf2_fit_ws = tfidf2.fit(all_df_ws['processed'].apply(str))\n",
    "tfidf2_fit_ws_kt = tfidf2_fit_ws.fit(all_df_kt['processed'].apply(str))\n",
    "\n",
    "joblib.dump(tfidf1_fit_ws, 'tfidf1_fit_ws.pkl')\n",
    "joblib.dump(tfidf1_fit_ws_kt, 'tfidf1_fit_ws_kt.pkl')\n",
    "joblib.dump(tfidf2_fit_ws, 'tfidf2_fit_ws.pkl')\n",
    "joblib.dump(tfidf2_fit_ws_kt, 'tfidf2_fit_ws_kt.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2867680",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8551fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, model):\n",
    "        w2v = {w: vec for w, vec in zip(model.wv.index_to_key, model.wv.vectors)}\n",
    "        self.word2vec = w2v\n",
    "        self.word2weight = None\n",
    "        self.dim = model.vector_size\n",
    "    \n",
    "    \n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "856dd1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21389"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from pythainlp import word_vector\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "# create word2vec models and intersect with the thai wiki pretrained one.\n",
    "\n",
    "w2v_model_ws = Word2Vec(vector_size=300, min_count=1, window = 5, workers=4)\n",
    "w2v_model_ws.build_vocab(all_df_ws['processed'])\n",
    "total_examples = w2v_model_ws.corpus_count\n",
    "total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee904ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51358"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_thwiki = word_vector.get_model()\n",
    "w2v_model_ws.build_vocab(w2v_thwiki.index_to_key, update=True)\n",
    "w2v_model_ws.wv.vectors_lockf = np.ones(len(w2v_model_ws.wv))\n",
    "w2v_model_ws.wv.intersect_word2vec_format('thai2vec.bin', binary=True, lockf=1.0)\n",
    "total_examples = w2v_model_ws.corpus_count\n",
    "total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af267111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42542754, 47151500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_ws.train(all_df_ws['processed'], total_examples=total_examples, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "872cbfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('‡∏Ç‡πâ‡∏≤‡∏ß‡∏°‡∏±‡∏ô‡πÑ‡∏Å‡πà', 0.39422789216041565),\n",
       " ('‡∏Å‡∏∏‡πâ‡∏á', 0.37291258573532104),\n",
       " ('‡πÑ‡πà‡∏Ç‡πà', 0.36208683252334595),\n",
       " ('‡πÑ‡∏Ç‡πà‡πÄ‡∏Ñ‡πá‡∏°', 0.3498747944831848),\n",
       " ('üç£', 0.3467874228954315),\n",
       " ('‡∏•‡∏π‡∏Å‡∏ä‡∏¥‡πâ‡∏ô', 0.34412676095962524),\n",
       " ('‡πÅ‡∏´‡∏ô‡∏°', 0.34077826142311096),\n",
       " ('‡∏´‡∏°‡∏π‡πÅ‡∏î‡∏á', 0.3383786678314209),\n",
       " ('‡πÉ‡∏™‡πâ', 0.32756781578063965),\n",
       " ('‡∏¢‡∏≥', 0.32196688652038574)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_ws.wv.most_similar(\"‡∏ö‡∏∞‡∏´‡∏°‡∏µ‡πà\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a18ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill # we use dill instead of joblim because the lambda and dependecie in class TfidfEmbeddingVectorizer\n",
    "# now we have our w2v mmodel, we need to convert single vector\n",
    "w2v_tfidf_emb_ws = TfidfEmbeddingVectorizer(w2v_model_ws)\n",
    "w2v_tifdf_fit_ws = w2v_tfidf_emb_ws.fit(all_df_ws['processed'])\n",
    "dill.dump(w2v_tifdf_fit_ws, open('w2v-tfidf_fit_ws.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df1f1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on new words from kt4.0 corpus\n",
    "w2v_model_ws.build_vocab(all_df_kt['processed'], update = True)\n",
    "total_examples = w2v_model_ws.corpus_count\n",
    "total_examples\n",
    "w2v_model_ws.train(all_df_kt['processed'], total_examples=total_examples, epochs=100)\n",
    "\n",
    "w2v_tfidf_emb_ws_kt = TfidfEmbeddingVectorizer(w2v_model_ws)\n",
    "w2v_tifdf_fit_ws_kt = w2v_tfidf_emb_ws_kt.fit(all_df_ws['processed'])\n",
    "dill.dump(w2v_tifdf_fit_ws_kt, open('w2v-tfidf_fit_ws_kt.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08d648bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('‡∏¢‡πà‡∏≤‡∏á', 0.3160748779773712),\n",
       " ('‡πÑ‡∏™‡πâ‡∏Å‡∏£‡∏≠‡∏Å', 0.2988615930080414),\n",
       " ('‡πÑ‡∏Å‡πà‡∏ö‡πâ‡∏≤‡∏ô', 0.28489479422569275),\n",
       " ('‡∏ä‡∏µ‡∏™', 0.28290531039237976),\n",
       " ('‡∏Å‡∏∞‡∏ó‡∏¥', 0.2817407250404358),\n",
       " ('‡∏ã‡∏∏‡∏õ', 0.2725837826728821),\n",
       " ('üçö', 0.272504061460495),\n",
       " ('‡πÅ‡∏°‡∏Ñ‡πÇ‡∏Ñ‡∏£', 0.261968731880188),\n",
       " ('‡∏´‡∏±‡∏ß‡πÑ‡∏ä‡πÄ‡∏ó‡πâ‡∏≤', 0.2597872018814087),\n",
       " ('‡πÄ‡∏Ñ‡πâ‡∏°', 0.2591487765312195)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_ws.wv.most_similar(\"‡∏ö‡∏∞‡∏´‡∏°‡∏µ‡πà\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102229e",
   "metadata": {},
   "source": [
    "## POS_Tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0387c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    l = list(sum(x, ()))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c257e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tag import pos_tag_sents\n",
    "\n",
    "# we used a POS tag with the orchid_ud feature that represented a type of word in a sentence in one-hot vector form\n",
    "# flatten the list of tuple in series was applied for feature vectors\n",
    "all_df_ws['POSTags'] = pos_tag_sents(all_df_ws['texts'].apply(str).apply(process_thai).tolist(), \\\n",
    "                                     corpus='orchid_ud')\n",
    "all_df_ws['POSTags'] = all_df_ws['POSTags'].apply(flatten)\n",
    "\n",
    "# TODO: concate word with pos (‡∏°‡∏±‡∏ô_ADV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f3755ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos2_fit_ws_kt.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos1 = CountVectorizer(ngram_range=(1, 1))\n",
    "pos2 = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "pos1_fit_ws = pos1.fit(all_df_ws['processed'].apply(str))\n",
    "pos1_fit_ws_kt = pos1_fit_ws.fit(all_df_kt['processed'].apply(str))\n",
    "\n",
    "pos2_fit_ws = pos2.fit(all_df_ws['processed'].apply(str))\n",
    "pos2_fit_ws_kt = pos2_fit_ws.fit(all_df_kt['processed'].apply(str))\n",
    "\n",
    "joblib.dump(pos1_fit_ws, 'pos1_fit_ws.pkl')\n",
    "joblib.dump(pos1_fit_ws_kt, 'pos1_fit_ws_kt.pkl')\n",
    "joblib.dump(pos2_fit_ws, 'pos2_fit_ws.pkl')\n",
    "joblib.dump(pos2_fit_ws_kt, 'pos2_fit_ws_kt.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f1e6f2",
   "metadata": {},
   "source": [
    "## Train-valid split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88c9ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_ws, valid_df_ws = train_test_split(all_df_ws, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abb484ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18180, 2395), (3209, 2395), (5348, 2395))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train_ws = tfidf2_fit_ws.transform(train_df_ws['texts'].apply(str))\n",
    "text_valid_ws = tfidf2_fit_ws.transform(valid_df_ws['texts'].apply(str))\n",
    "text_test_ws = tfidf2_fit_ws.transform(test_df_ws['texts'].apply(str))\n",
    "text_train_ws.shape, text_valid_ws.shape, text_test_ws.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a39ac867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neu    0.548146\n",
       "neg    0.246183\n",
       "pos    0.180118\n",
       "q      0.025553\n",
       "Name: targets, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_ws.targets.value_counts() / valid_df_ws.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2917489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07882556] [0.75324233]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((18180, 1), (3209, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The calculated sentiment and word count features might be useful, so we concat them to the text feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler_fit = scaler.fit(np.asarray(all_df_ws['cal_sentiment']).reshape(-1, 1))\n",
    "print(scaler_fit.mean_, scaler_fit.var_)\n",
    "\n",
    "cal_sent_train = scaler_fit.transform(np.asarray(train_df_ws['cal_sentiment']).reshape(-1, 1).astype(float))\n",
    "cal_sent_valid = scaler_fit.transform(np.asarray(valid_df_ws['cal_sentiment']).reshape(-1, 1).astype(float))\n",
    "cal_sent_test = scaler_fit.transform(np.asarray(test_df_ws['cal_sentiment']).reshape(-1, 1).astype(float))\n",
    "cal_sent_train.shape, cal_sent_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3ad41d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.04474262] [1169.8183263]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((18180, 1), (3209, 1))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_fit = scaler.fit(np.asarray(all_df_ws['wc']).reshape(-1, 1))\n",
    "print(scaler_fit.mean_, scaler_fit.var_)\n",
    "\n",
    "num_train = scaler_fit.transform(np.asarray(train_df_ws['wc']).reshape(-1, 1).astype(float))\n",
    "num_valid = scaler_fit.transform(np.asarray(valid_df_ws['wc']).reshape(-1, 1).astype(float))\n",
    "num_test = scaler_fit.transform(np.asarray(test_df_ws['wc']).reshape(-1, 1).astype(float))\n",
    "num_train.shape, num_valid.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159c026",
   "metadata": {},
   "source": [
    "## Test the extracted features with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a96c00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18180, 2397), (3209, 2397))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_df_ws['targets']\n",
    "y_valid = valid_df_ws['targets']\n",
    "\n",
    "# concat text vector and generated feature vectors\n",
    "X_train = np.concatenate([text_train_ws.toarray(), cal_sent_train, num_train], axis=1)\n",
    "X_valid = np.concatenate([text_valid_ws.toarray(), cal_sent_valid, num_valid], axis=1)\n",
    "X_test = np.concatenate([text_test_ws.toarray(), cal_sent_test, num_test], axis=1)\n",
    "\n",
    "#X_train = text_train_ws.toarray()\n",
    "#X_valid = text_valid_ws.toarray()\n",
    "#X_test = text_test_ws.toarray()\n",
    "\n",
    "#X_train = text_train_ws\n",
    "#X_valid  = text_valid_ws\n",
    "#X_test = text_test_ws\n",
    "\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc1413dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5687129947023996"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick test with out cv\n",
    "#fit logistic regression models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=2., penalty=\"l2\", solver=\"liblinear\", dual=False, multi_class=\"ovr\")\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_valid, y_valid)\n",
    "#y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f340fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(y_pred) \n",
    "# this might cause from label 'q' is not present in the y_pred (due to the severe imbalance class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6282242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "def build_model(model):\n",
    "    scores = (cross_val_score(model, X_train, y_train, cv = 5).mean())\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    acc_sc = accuracy_score(y_valid, y_pred)\n",
    "    pre_sc = precision_score(y_valid, y_pred, average='weighted')\n",
    "    rec_sc = recall_score(y_valid, y_pred, average='weighted')\n",
    "    f1_sc = f1_score(y_valid, y_pred, average='weighted')\n",
    "    print('Accuracy :',acc_sc)\n",
    "    print('Confusion Matrix :\\n', confusion_matrix(y_valid, y_pred))\n",
    "    print('Precision :', pre_sc)\n",
    "    print('Recall :', rec_sc)\n",
    "    print('F1-score :', f1_sc)\n",
    "    print('Classification Report :\\n', classification_report(y_valid, y_pred))\n",
    "    print('Average accuracy of k-fold (5-fold) :', scores ,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e120d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.5687129947023996\n",
      "Confusion Matrix :\n",
      " [[ 112  656   22    0]\n",
      " [  65 1677   17    0]\n",
      " [  20  522   36    0]\n",
      " [   0   80    2    0]]\n",
      "Precision : 0.5373724095592892\n",
      "Recall : 0.5687129947023996\n",
      "F1-score : 0.467336708171298\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.57      0.14      0.23       790\n",
      "         neu       0.57      0.95      0.71      1759\n",
      "         pos       0.47      0.06      0.11       578\n",
      "           q       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.57      3209\n",
      "   macro avg       0.40      0.29      0.26      3209\n",
      "weighted avg       0.54      0.57      0.47      3209\n",
      "\n",
      "Average accuracy of k-fold (5-fold) : 0.5613861386138613 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pree\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pree\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pree\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Pree\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "build_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12a8761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(y_pred) \n",
    "# this might cause from label 'q' is not present in the y_pred (due to the severe imbalance class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
