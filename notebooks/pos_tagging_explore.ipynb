{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore difference POS tagging strategy that available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'onehot_mean' from 'src.feature.postag_transform' (C:\\Users\\Pree\\Thai_SA_journal\\src\\feature\\postag_transform.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Pree\\Thai_SA_journal\\notebooks\\pos_tagging_explore.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pree/Thai_SA_journal/notebooks/pos_tagging_explore.ipynb#ch0000001?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder, OneHotEncoder, LabelBinarizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pree/Thai_SA_journal/notebooks/pos_tagging_explore.ipynb#ch0000001?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpythainlp\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m pos_tag_sents\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Pree/Thai_SA_journal/notebooks/pos_tagging_explore.ipynb#ch0000001?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpostag_transform\u001b[39;00m \u001b[39mimport\u001b[39;00m onehot_mean, word_tag, tag, tag_emoj, flatten\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'onehot_mean' from 'src.feature.postag_transform' (C:\\Users\\Pree\\Thai_SA_journal\\src\\feature\\postag_transform.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer\n",
    "from pythainlp.tag import pos_tag_sents\n",
    "from src.feature.postag_transform import onehot_label, word_tag, tag, tag_emoj, flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Pree\\\\Thai_SA_journal\\\\data\\\\processed\\\\wisesight.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = df['processed'].iloc[1000:1100]\n",
    "tagged = pos_tag_sents(feat.apply(ast.literal_eval).values.tolist(), corpus='orchid_ud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use only tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag = tag(tagged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join word and tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag = word_tag(tagged)\n",
    "print(pos_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = flatten(tagged)\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoded vector for each POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pos_tag_ud = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
    "pos_tag_arr = np.array(pos_tag_ud)\n",
    "\n",
    "# use sklearn libs seem more reliable than the sorted dict-based approach\n",
    "le = LabelEncoder().fit(pos_tag_arr)\n",
    "pos_tag_ud_transformed = le.transform(pos_tag_arr)\n",
    "ohe = OneHotEncoder().fit(pos_tag_ud_transformed.reshape((-1,1)))\n",
    "onehot_data = ohe.transform(pos_tag_ud_transformed.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_ud_arr = np.array(pos_tag_ud)\n",
    "lb = LabelBinarizer().fit(pos_tag_ud_arr)\n",
    "onehot_data = lb.transform(pos_tag_ud_arr)\n",
    "print(onehot_data, lb.inverse_transform(onehot_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [el[1] for el in tagged[0]]\n",
    "tag_only = ' '.join(map(str, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_data = list(tag_only.split(\" \"))\n",
    "tag_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texty_data = np.array(tag_data)\n",
    "onehot_data = lb.transform(texty_data)\n",
    "print(onehot_data, lb.inverse_transform(onehot_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now deal with n tagged as a function\n",
    "import numpy as np\n",
    "def onehot_label(tagged):\n",
    "        pos_tag_ud = ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n",
    "        pos_tag_ud_arr = np.array(pos_tag_ud)\n",
    "        tag_list = []\n",
    "    \n",
    "        for item in tagged:\n",
    "                lb = LabelBinarizer().fit(pos_tag_ud_arr)\n",
    "                tmp = [el[1] for el in item]\n",
    "                tag_only = ' '.join(map(str, tmp))\n",
    "                tag_only = list(tag_only.split(\" \"))\n",
    "                onehot_data = lb.transform(tag_only)\n",
    "                tag_list.append(onehot_data)\n",
    "        return  tag_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the implemented function real quick here.\n",
    "pos_tag = onehot_label(tagged) \n",
    "pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MeanEmbeddingVectorizer(object):\n",
    "#     def __init__(self, pos_tag):\n",
    "#         self.pos_tag = pos_tag\n",
    "#         # if a text is empty we should return a vector of zeros\n",
    "#         # with the same dimensionality as all the other vectors\n",
    "#         self.dim = len(word2vec.wv.syn0[0])\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         X = MyTokenizer().fit_transform(X)\n",
    "        \n",
    "#         return np.array([\n",
    "#             np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
    "#                     or [np.zeros(self.dim)], axis=0)\n",
    "#             for words in X\n",
    "#         ])\n",
    "    \n",
    "#     def fit_transform(self, X, y=None):\n",
    "#         return self.transform(X)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "383230589b3bed323826e90250be508b8c998b038ed3228ac76634bbf0db629d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('scientificProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
