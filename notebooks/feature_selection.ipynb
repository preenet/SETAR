{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf2df5f",
   "metadata": {},
   "source": [
    "## Feature selection using two-stage filtering method  \n",
    "We applied a two-stage filtering feature selection method for both bow and tfi-df text representations only.    \n",
    "filter 1 - remove feature with low variance  \n",
    "filter 2 - remove redundant features using MI score   \n",
    "\n",
    "pree.t@cmu.ac.th  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b18ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.path.dirname(os.getcwd())\n",
    "model_path = os.path.dirname(os.getcwd()) + '\\\\model\\\\original\\\\'\n",
    "model_path_fs_train = os.path.dirname(os.getcwd()) + '\\\\model\\\\feature selection\\\\train\\\\'\n",
    "model_path_fs_test = os.path.dirname(os.getcwd()) + '\\\\model\\\\feature selection\\\\test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280c10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing all data \n",
    "feat1, y1 = joblib.load(model_path+'text_bow1_kt.pkl')\n",
    "feat2, y2 = joblib.load(model_path+'text_bow1_ws.pkl')\n",
    "feat3, y3 = joblib.load(model_path+'text_bow2_kt.pkl')\n",
    "feat4, y4 = joblib.load(model_path+'text_bow2_ws.pkl')\n",
    "feat5, y5 = joblib.load(model_path+'text_tfidf1_kt.pkl')\n",
    "feat6, y6 = joblib.load(model_path+'text_tfidf1_ws.pkl')\n",
    "feat7, y7 = joblib.load(model_path+'text_tfidf2_kt.pkl')\n",
    "feat8, y8 = joblib.load(model_path+'text_tfidf2_ws.pkl')\n",
    "\n",
    "all_feats = [[\"text_bow1_kt\", feat1, y1],\n",
    "               [\"text_bow1_ws\", feat2, y2],\n",
    "               [\"text_bow2_kt\", feat3, y3],\n",
    "               [\"text_bow2_ws\", feat4, y4],\n",
    "               [\"text_tfidf1_kt\", feat5, y5],\n",
    "               [\"text_tfidf1_ws\", feat6, y6],\n",
    "               [\"text_tfidf2_kt\", feat7, y7],\n",
    "               [\"text_tfidf2_ws\", feat8, y8]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef91f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split 80/20 for all text representations\n",
    "from sklearn.model_selection import train_test_split\n",
    "for i in range(len(all_feats)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_feats[i][1], all_feats[i][2], train_size=0.8, test_size=0.2)\n",
    "    all_feats[i].extend([X_train, X_test, y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_scores(threshold_val):\n",
    "    fig = plt.figure(figsize=(9, 7), dpi=80) \n",
    "    ax = plt.axes()\n",
    "    ax.axhline(threshold_val, ls='dotted', c='r')\n",
    "    ax.plot(vt.variances_)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ddd3f",
   "metadata": {},
   "source": [
    "## Select using fixed dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ef688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def twosteps_fs(X, y, vt_dim, mi_dim):\n",
    "        '''\n",
    "        parem:  X = features, y = target\n",
    "                vt_dim = dimension for first filter,\n",
    "                mi_dim = diminsion last filter\n",
    "        return: array \n",
    "        '''\n",
    "        vt = VarianceThreshold()\n",
    "        vt.fit(X)\n",
    "        feature_scores = vt.variances_\n",
    "\n",
    "        idx = np.flip(np.argsort(feature_scores))\n",
    "        tmp = np.take(X, idx.flatten(), axis=1)        \n",
    "        X_vt = tmp[:, :vt_dim]\n",
    "\n",
    "        feature_scores = mutual_info_classif(X_vt, np.ravel(y), random_state=0)\n",
    "        mi_idx = np.flip(np.argsort(feature_scores))\n",
    "        tmp = np.take(X_vt, mi_idx.flatten(), axis=1)        \n",
    "        X_vt_mi = tmp[:, :mi_dim]\n",
    "        return X_vt_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vt_dim = 1500\n",
    "mi_dim = 700\n",
    "for i in range(len(all_feats)):\n",
    "    print(\"selecting: \", all_feats[i][0])\n",
    "    # fs on training set\n",
    "    X = all_feats[i][3].A\n",
    "    y = all_feats[i][5].A\n",
    "    X_vt_mi = twosteps_fs(X, y, vt_dim, mi_dim)\n",
    "    arr = np.hstack((sparse.csr_matrix(X_vt_mi), sparse.csr_matrix(y)))\n",
    "    joblib.dump(arr, model_path + all_feats[i][0] + \"_fs_train.pkl\")\n",
    "\n",
    "    # fs on testing set\n",
    "    X = all_feats[i][4].A\n",
    "    y = all_feats[i][6].A\n",
    "    X_vt_mi = twosteps_fs(X, y, vt_dim, mi_dim)\n",
    "    arr = np.hstack((sparse.csr_matrix(X_vt_mi), sparse.csr_matrix(y)))\n",
    "    joblib.dump(arr, model_path + all_feats[i][0] + \"_fs_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132b564",
   "metadata": {},
   "source": [
    "## Manually select using specfic thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select using manual threshold\n",
    "X = all_feats[0][3].A\n",
    "y = all_feats[0][5].A\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7335f6",
   "metadata": {},
   "source": [
    "## Filter 1 - remove features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e25fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow1_kt 0.00035\n",
    "# bow1_ws 0.003\n",
    "# bow2_kt 0.00065\n",
    "# bow2_ws\n",
    "# tfidf1_kt\n",
    "# tfidf1_ws\n",
    "# tfidf2_kt\n",
    "# tfidf2_ws\n",
    "threshold_val = 0.00035\n",
    "vt = VarianceThreshold(threshold=threshold_val)\n",
    "vt.fit(X)\n",
    "mask = vt.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(mask==False)\n",
    "print(\"total number of feature will be removed:\", len(idx[0]))\n",
    "X_vt =  np.delete(X, idx, 1)\n",
    "X_vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b043c0",
   "metadata": {},
   "source": [
    "## Filter 2 remove using MI score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcuate mi score of the remaining terms\n",
    "feature_scores = mutual_info_classif(X_vt, np.ravel(y), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72043604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow1_kt = 0.0001\n",
    "# bow1_ws = 0.0005\n",
    "mi_threshold_val = 0.0001\n",
    "plot_feature_scores(mi_threshold_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425dadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set another mi score threshold manually, so that we can have reasonable size\n",
    "plt.plot(-np.sort(-feature_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores_final = feature_scores[feature_scores > mi_threshold_val]\n",
    "plt.plot(-np.sort(-feature_scores_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cffd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select with threshold\n",
    "mi_idx = np.argwhere(feature_scores > mi_threshold_val)\n",
    "X_vt_mi = np.take(X_vt, mi_idx.flatten(), axis=1)\n",
    "X_vt_mi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.hstack((sparse.csr_matrix(X_vt_mi), sparse.csr_matrix(y)))\n",
    "joblib.dump(arr, model_path+'text_bow1_ws_fs.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df00a88",
   "metadata": {},
   "source": [
    "## Test with LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f33e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat1, y1 = joblib.load(model_path_fs_train+'text_bow1_kt_fs_train.pkl')\n",
    "feat2, y2 = joblib.load(model_path_fs_train+'text_bow1_ws_fs_train.pkl')\n",
    "feat3, y3 = joblib.load(model_path_fs_train+'text_bow2_kt_fs_train.pkl')\n",
    "feat4, y4 = joblib.load(model_path_fs_train+'text_bow2_ws_fs_train.pkl')\n",
    "feat5, y5 = joblib.load(model_path_fs_train+'text_tfidf1_kt_fs_train.pkl')\n",
    "feat6, y6 = joblib.load(model_path_fs_train+'text_tfidf1_ws_fs_train.pkl')\n",
    "feat7, y7 = joblib.load(model_path_fs_train+'text_tfidf2_kt_fs_train.pkl')\n",
    "feat8, y8 = joblib.load(model_path_fs_train+'text_tfidf2_ws_fs_train.pkl')\n",
    "\n",
    "all_feats_fs_train = [[\"text_bow1_kt_fs_train\", feat1, y1],\n",
    "               [\"text_bow1_ws_fs_train\", feat2, y2],\n",
    "               [\"text_bow2_kt_fs_train\", feat3, y3],\n",
    "               [\"text_bow2_ws_fs_train\", feat4, y4],\n",
    "               [\"text_tfidf1_kt_fs_train\", feat5, y5],\n",
    "               [\"text_tfidf1_ws_fs_train\", feat6, y6],\n",
    "               [\"text_tfidf2_kt_fs_train\", feat7, y7],\n",
    "               [\"text_tfidf2_ws_fs_train\", feat8, y8]\n",
    "            ]\n",
    "\n",
    "feat1, y1 = joblib.load(model_path_fs_test+'text_bow1_kt_fs_test.pkl')\n",
    "feat2, y2 = joblib.load(model_path_fs_test+'text_bow1_ws_fs_test.pkl')\n",
    "feat3, y3 = joblib.load(model_path_fs_test+'text_bow2_kt_fs_test.pkl')\n",
    "feat4, y4 = joblib.load(model_path_fs_test+'text_bow2_ws_fs_test.pkl')\n",
    "feat5, y5 = joblib.load(model_path_fs_test+'text_tfidf1_kt_fs_test.pkl')\n",
    "feat6, y6 = joblib.load(model_path_fs_test+'text_tfidf1_ws_fs_test.pkl')\n",
    "feat7, y7 = joblib.load(model_path_fs_test+'text_tfidf2_kt_fs_test.pkl')\n",
    "feat8, y8 = joblib.load(model_path_fs_test+'text_tfidf2_ws_fs_test.pkl')\n",
    "\n",
    "all_feats_fs_test = [[\"text_bow1_kt_fs_train\", feat1, y1],\n",
    "               [\"text_bow1_ws_fs_test\", feat2, y2],\n",
    "               [\"text_bow2_kt_fs_test\", feat3, y3],\n",
    "               [\"text_bow2_ws_fs_test\", feat4, y4],\n",
    "               [\"text_tfidf1_kt_fs_test\", feat5, y5],\n",
    "               [\"text_tfidf1_ws_fs_test\", feat6, y6],\n",
    "               [\"text_tfidf2_kt_fs_test\", feat7, y7],\n",
    "               [\"text_tfidf2_ws_fs_test\", feat8, y8]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42524d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with the original:\n",
      "text_bow1_kt: val=  0.7417 , test=  0.7472\n",
      "text_bow1_ws: val=  0.6728 , test=  0.6774\n",
      "text_bow2_kt: val=  0.7181 , test=  0.7223\n",
      "text_bow2_ws: val=  0.6272 , test=  0.6189\n",
      "text_tfidf1_kt: val=  0.7514 , test=  0.7504\n",
      "text_tfidf1_ws: val=  0.6928 , test=  0.6943\n",
      "text_tfidf2_kt: val=  0.7244 , test=  0.7268\n",
      "text_tfidf2_ws: val=  0.626 , test=  0.623\n"
     ]
    }
   ],
   "source": [
    "# test with original\n",
    "print(\"Performance with the original:\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=2., penalty=\"l2\", solver=\"liblinear\", dual=False, multi_class=\"ovr\")\n",
    "\n",
    "for i in range(len(all_feats)):\n",
    "    # train-test split 80/20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_feats[i][1], all_feats[i][2], test_size=0.2, random_state=0)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train.A, np.ravel(y_train.A), test_size=0.25, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(all_feats[i][0] + \": val= \", round(model.score(X_valid, y_valid), 4), \", test= \" , round(model.score(X_test.A, np.ravel(y_test.A)), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af377b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with the proposed feature selection:\n",
      "text_bow1_kt_fs_train: val=  0.7123 , test=  0.7114\n",
      "text_bow1_ws_fs_train: val=  0.6681 , test=  0.6568\n",
      "text_bow2_kt_fs_train: val=  0.6728 , test=  0.6735\n",
      "text_bow2_ws_fs_train: val=  0.5849 , test=  0.5853\n",
      "text_tfidf1_kt_fs_train: val=  0.7131 , test=  0.7158\n",
      "text_tfidf1_ws_fs_train: val=  0.6655 , test=  0.6774\n",
      "text_tfidf2_kt_fs_train: val=  0.67 , test=  0.6763\n",
      "text_tfidf2_ws_fs_train: val=  0.5951 , test=  0.6047\n"
     ]
    }
   ],
   "source": [
    "# test with two-step fs (train)\n",
    "print(\"Performance with the proposed feature selection:\")\n",
    "for i in range(len(all_feats_fs_train)):\n",
    "    # train-test split 80/20\n",
    "    X_train, X_test, y_train, y_test = train_test_split(all_feats_fs_train[i][1], all_feats_fs_train[i][2], test_size=0.2, random_state=0)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train.A, np.ravel(y_train.A), test_size=0.25, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(all_feats_fs_train[i][0] + \": val= \", round(model.score(X_valid, y_valid), 4), \", test= \" , round(model.score(X_test.A, np.ravel(y_test.A)), 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
