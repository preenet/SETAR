{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf2df5f",
   "metadata": {},
   "source": [
    "## Feature selection using two-stage filtering method  \n",
    "We applied a two-stage filtering feature selection method for both bow and tfi-df text representation only.    \n",
    "filter 1 - remove feature with low variance  \n",
    "filter 2 - remove redundant features using MI score   \n",
    "\n",
    "pree.t@cmu.ac.th  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b18ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.path.dirname(os.getcwd())\n",
    "\n",
    "model_path = os.path.dirname(os.getcwd()) + '\\\\model\\\\'\n",
    "lexicon_path = os.path.dirname(os.getcwd()) + '\\\\lexicon\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280c10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing all data \n",
    "\n",
    "text_bow1_kt = joblib.load(model_path+'text_bow1_kt.pkl')\n",
    "text_bow1_ws = joblib.load(model_path+'text_bow1_ws.pkl')\n",
    "\n",
    "text_bow2_kt = joblib.load(model_path+'text_bow2_kt.pkl')\n",
    "text_bow2_ws = joblib.load(model_path+'text_bow2_ws.pkl')\n",
    "\n",
    "text_tfidf1_kt = joblib.load(model_path+'text_tfidf1_kt.pkl')\n",
    "text_tfidf1_ws = joblib.load(model_path+'text_tfidf1_ws.pkl')\n",
    "\n",
    "text_tfidf2_kt = joblib.load(model_path+'text_tfidf2_kt.pkl')\n",
    "text_tfidf2_ws = joblib.load(model_path+'text_tfidf2_ws.pkl')\n",
    "\n",
    "all_texts = [[\"text_bow1_kt\", text_bow1_kt],\n",
    "               [\"text_bow1_ws\", text_bow1_ws],\n",
    "               [\"text_bow2_kt\", text_bow2_kt],\n",
    "               [\"text_bow2_ws\", text_bow2_ws],\n",
    "               [\"text_tfidf1_kt\", text_tfidf1_kt],\n",
    "               [\"text_tfidf1_ws\", text_tfidf1_ws],\n",
    "               [\"text_tfidf2_kt\", text_tfidf2_kt],\n",
    "               [\"text_tfidf2_ws\", text_tfidf2_ws]\n",
    "            ]\n",
    "# lex_bow1_kt = joblib.load(lexicon_path+'lex_bow1_kt.pkl')\n",
    "# lex_bow1_ws = joblib.load(lexicon_path+'lex_bow1_ws.pkl')\n",
    "\n",
    "# lex_bow2_kt = joblib.load(lexicon_path+'lex_bow2_kt.pkl')\n",
    "# lex_bow2_ws = joblib.load(lexicon_path+'lex_bow2_ws.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2bf8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_scores(threshold_val):\n",
    "    fig = plt.figure(figsize=(9, 7), dpi=80) \n",
    "    ax = plt.axes()\n",
    "    ax.axhline(threshold_val, ls='dotted', c='r')\n",
    "    ax.plot(vt.variances_)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ddd3f",
   "metadata": {},
   "source": [
    "## Select using fix dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06ef688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "parem:  X = features, y= target\n",
    "        vt_dim = dimension for first filter,\n",
    "        mi_dim = diminsion last filter\n",
    "return: array \n",
    "'''\n",
    "def twosteps_fs(X, y, vt_dim, mi_dim):\n",
    "        vt = VarianceThreshold()\n",
    "        vt.fit(X)\n",
    "        feature_scores = vt.variances_\n",
    "\n",
    "        idx = np.flip(np.argsort(feature_scores))\n",
    "        tmp = np.take(X, idx.flatten(), axis=1)        \n",
    "        X_vt = tmp[:, :vt_dim]\n",
    "\n",
    "        feature_scores = mutual_info_classif(X_vt, np.ravel(y), random_state=0)\n",
    "        mi_idx = np.flip(np.argsort(feature_scores))\n",
    "        tmp = np.take(X_vt, mi_idx.flatten(), axis=1)        \n",
    "        X_vt_mi = tmp[:, :mi_dim]\n",
    "        return X_vt_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba0907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 29min 31s\n",
      "Wall time: 29min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vt_dim = 1500\n",
    "mi_dim = 700\n",
    "for i in range(len(all_texts)):\n",
    "    X, y = all_texts[i][1]\n",
    "    X = X.A\n",
    "    y = y.A\n",
    "    X_vt_mi = twosteps_fs(X, y, vt_dim, mi_dim)\n",
    "\n",
    "    arr = np.hstack((sparse.csr_matrix(X_vt_mi), sparse.csr_matrix(y)))\n",
    "    joblib.dump(arr, model_path + all_texts[i][0] + \"_fs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132b564",
   "metadata": {},
   "source": [
    "## Manually select using specfic thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select using manual threshold\n",
    "X, y = text_bow1_kt\n",
    "X = X.A\n",
    "y = y.A\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7335f6",
   "metadata": {},
   "source": [
    "## Filter 1 - remove features with low variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e25fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow1_kt 0.00035\n",
    "# bow1_ws 0.003\n",
    "# bow2_kt 0.00065\n",
    "# bow2_ws\n",
    "# tfidf1_kt\n",
    "# tfidf1_ws\n",
    "# tfidf2_kt\n",
    "# tfidf2_ws\n",
    "threshold_val = 0.00035\n",
    "vt = VarianceThreshold(threshold=threshold_val)\n",
    "vt.fit(X)\n",
    "mask = vt.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(mask==False)\n",
    "print(\"total number of feature will be removed:\", len(idx[0]))\n",
    "X_vt =  np.delete(X, idx, 1)\n",
    "X_vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b043c0",
   "metadata": {},
   "source": [
    "## Filter 2 remove using MI score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcuate mi score of the remaining terms\n",
    "feature_scores = mutual_info_classif(X_vt, np.ravel(y), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72043604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bow1_kt = 0.0001\n",
    "# bow1_ws = 0.0005\n",
    "mi_threshold_val = 0.0001\n",
    "plot_feature_scores(mi_threshold_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425dadf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set another mi score threshold manually, so that we can have reasonable size\n",
    "plt.plot(-np.sort(-feature_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c18b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores_final = feature_scores[feature_scores > mi_threshold_val]\n",
    "plt.plot(-np.sort(-feature_scores_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cffd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select with threshold\n",
    "mi_idx = np.argwhere(feature_scores > mi_threshold_val)\n",
    "X_vt_mi = np.take(X_vt, mi_idx.flatten(), axis=1)\n",
    "X_vt_mi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_new = np.hstack((sparse.csr_matrix(X_vt_mi), sparse.csr_matrix(y)))\n",
    "joblib.dump(arr_new, model_path+'text_bow1_ws_kt.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df00a88",
   "metadata": {},
   "source": [
    "## Test with LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f33e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bow1_kt_fs = joblib.load(model_path+'text_bow1_kt_fs.pkl')\n",
    "text_bow1_ws_fs = joblib.load(model_path+'text_bow1_ws_fs.pkl')\n",
    "\n",
    "text_bow2_kt_fs = joblib.load(model_path+'text_bow2_kt_fs.pkl')\n",
    "text_bow2_ws_fs = joblib.load(model_path+'text_bow2_ws_fs.pkl')\n",
    "\n",
    "text_tfidf1_kt_fs = joblib.load(model_path+'text_tfidf1_kt_fs.pkl')\n",
    "text_tfidf1_ws_fs = joblib.load(model_path+'text_tfidf1_ws_fs.pkl')\n",
    "\n",
    "text_tfidf2_kt_fs = joblib.load(model_path+'text_tfidf2_kt_fs.pkl')\n",
    "text_tfidf2_ws_fs = joblib.load(model_path+'text_tfidf2_ws_fs.pkl')\n",
    "\n",
    "all_texts_fs = [[\"text_bow1_kt_fs\", text_bow1_kt_fs],\n",
    "               [\"text_bow1_ws_fs\", text_bow1_ws_fs],\n",
    "               [\"text_bow2_kt_fs\", text_bow2_kt_fs],\n",
    "               [\"text_bow2_ws_fs\", text_bow2_ws_fs],\n",
    "               [\"text_tfidf1_kt_fs\", text_tfidf1_kt_fs],\n",
    "               [\"text_tfidf1_ws_fs\", text_tfidf1_ws_fs],\n",
    "               [\"text_tfidf2_kt_fs\", text_tfidf2_kt_fs],\n",
    "               [\"text_tfidf2_ws_fs\", text_tfidf2_ws_fs]\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73fe13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40f4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better use train test split sklearn twice\n",
    "def train_val_test_split(X, y, train_size, val_size, test_size):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = test_size, random_state=42)\n",
    "    relative_train_size = train_size / (val_size + train_size)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_val, y_train_val,\n",
    "                                                      train_size = relative_train_size, test_size = 1-relative_train_size)\n",
    "    return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42524d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_bow1_kt: val=  0.7163 , test=  0.7198\n",
      "text_bow1_ws: val=  0.6591 , test=  0.6668\n",
      "text_bow2_kt: val=  0.6826 , test=  0.6755\n",
      "text_bow2_ws: val=  0.5933 , test=  0.5877\n",
      "text_tfidf1_kt: val=  0.7214 , test=  0.7174\n",
      "text_tfidf1_ws: val=  0.6758 , test=  0.6739\n",
      "text_tfidf2_kt: val=  0.6729 , test=  0.6785\n",
      "text_tfidf2_ws: val=  0.5957 , test=  0.5929\n"
     ]
    }
   ],
   "source": [
    "# test with original\n",
    "model = LogisticRegression(C=2., penalty=\"l2\", solver=\"liblinear\", dual=False, multi_class=\"ovr\")\n",
    "for i in range(len(all_texts)):\n",
    "    X = all_texts_fs[i][1][0].A\n",
    "    y = all_texts_fs[i][1][1].A\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = train_val_test_split(X, np.ravel(y), train_size=0.6, val_size=0.2, test_size=0.2)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(all_texts[i][0] + \": val= \", str(round(model.score(X_valid, y_valid), 4)), \", test= \" , str(round(model.score(X_test, y_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af377b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_bow1_kt_fs: val=  0.7186 , test=  0.7201\n",
      "text_bow1_ws_fs: val=  0.6614 , test=  0.6668\n",
      "text_bow2_kt_fs: val=  0.6667 , test=  0.6753\n",
      "text_bow2_ws_fs: val=  0.5927 , test=  0.5849\n",
      "text_tfidf1_kt_fs: val=  0.7181 , test=  0.7182\n",
      "text_tfidf1_ws_fs: val=  0.6694 , test=  0.6743\n",
      "text_tfidf2_kt_fs: val=  0.6713 , test=  0.6783\n",
      "text_tfidf2_ws_fs: val=  0.5944 , test=  0.5944\n"
     ]
    }
   ],
   "source": [
    "# test with original\n",
    "for i in range(len(all_texts_fs)):\n",
    "    X = all_texts_fs[i][1][0].A\n",
    "    y = all_texts_fs[i][1][1].A\n",
    "    X_train, X_valid, X_test, y_train, y_valid, y_test = train_val_test_split(X, np.ravel(y), train_size=0.6, val_size=0.2, test_size=0.2)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(all_texts_fs[i][0] + \": val= \", str(round(model.score(X_valid, y_valid), 4)), \", test= \" , str(round(model.score(X_test, y_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c31b513",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
